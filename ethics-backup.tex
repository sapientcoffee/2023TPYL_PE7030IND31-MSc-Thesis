\documentclass[man]{apa7}
\usepackage[british]{babel}
\usepackage{csquotes}
\usepackage[style=apa,sortcites=true,sorting=nyt,backend=biber]{biblatex}
\DeclareLanguageMapping{british}{british-apa}
\addbibresource{references.bib}

\title{Measuring cognitive performance of software engineers using AI assisted development}

\begin{document}
\maketitle
\onecolumn

\section{Background}
The software engineering and software development industry now offers assisted development solutions with generative artificial intelligence (AI; \cite{Nguyen-Duc2023GenerativeAgenda}). The emergence of these solutions over the last couple of years is due to the ... LLM ..... These solutions are often embedded into the Integrated Development Environment (IDE) helping with common activities, code explanations, code completion and analysis. The IDE is an integral part of the software development and developers spend up to xxx\% of their time working in it \parencite{}. The hope exists that these solutions will make the life easier for developers to do their job allowing them to focus more of their mental effort to solve programming challenges. We will investigate the impact on cognitive effort for software engineers when AI capabilities are embedded into their IDE.

In the realm of cognitive psychology, 'cognition' encompasses a collection of thoughts and concepts, representing the internal mental operations or cognitive processes. These cognitive functions oversee human perception, logical reasoning, memory, intuition, thought processes, verbal communication, decision-making, and the resolution of problems \parencite{}(Roy 2013; Benjafield et al. 2010).

Cognitive effort, in the context of software development or engineering, comes from mentally processes the structure of source code, known as source code comprehension \parencite{Crk2016AssessingComprehension, Crk2015UnderstandingExpertise} and interpreting different abstraction levels of software artefacts \parencite{Minas2017NeurophysiologicalDevelopers}. 

The measurement of cognitive effort has helped better understand software engineering (such as the level of expertise of developers) \parencite{Crk2016AssessingComprehension, Crk2015UnderstandingExpertise}, e.g, for accounting developers programming experience, and classification of the perceived difficulty \parencite{Fritz2014UsingDevelopment, Fritz2016LeveragingProductivity} during a coding task.

To solve complex tasks developers' cognitive effort will increase, the goal of AI is not to remove all the cognitive effort but to reduce the cognitive load, mental workload (such as implementing the correct code syntax), that impedes value creation or solving tasks and increase the reserve mental capacity to solve tasks. Mental workload is the level of activation of a finite pool of resources the individual has while cognitive processing a primary task over time with the devotion of their effort and attention \parencite{Longo2022HumanDefinition}.

Cognition processes are not directly observable, but their assessment can be conducted indirectly through psychometrics, utilising specific tests. Psychometric evaluations, which could include questionnaires or exercises, are designed to gauge cognitive functions through metrics \parencite{} (Gellman and Turner 2013; Allan 2013). The measurement of cognitive effort for software developers has commonly has leveraged objective physiological measurements (e.g. EEG \parencite{Jatupaiboon2013EmotionBands, Minas2017NeurophysiologicalDevelopers}, eye-tracking \parencite{Fritz2014UsingDevelopment} or dilation, heart rate or fMRI) with controlled experiments \parencite{Goncales2019MeasuringStudy} however these do not offer a subjective perspective from developers. Human-Computer Interaction research (HCI), the intersection of psychology, social science and computer science and technology \parencite{Carroll1997Human-computerDesign}, research into cognitive effort and the use of AI in the IDE has not yet been conducted. To better understand the subjective experience of individuals in relation to the interface between AI and developers a questionnaire will be used, this also follows the tradition in HCI research for measuring mental demands of  cognitive workload \parencite{Kosch2023AInteraction}. The questionnaire will be combined with code challenges in which the participants will complete leveraging both AI enabled and disabled in their IDE completing the survey to capture their experience. NASA Task Load IndeX (TLX) and Workload profile (WP) will be used, they are complementary to each other, using different theoretical and methodological approaches therefore compensating for individual limitations \parencite{Rubio2004EvaluationMethods, Paxion2014Complexite}. TLX is based on a methodological model and WP based on Multiple Resource Theory (MRT) \parencite{Wickens1984ProcessingAttention, Wickens2008MultipleWorkload, Wickens2020ProcessingAttention}.

Measure cognitive performance with SW engineering
3 predictors to subjectively assess
% No more than 2 predictors (AI, developmental - cognitive load)

\emph{Research Question 1 (RQ1)}. To what extent does AI  ... cognitive load  .. simple and complex

\emph{Research Question 2 (RQ2)}. .... ... ..  

% https://link.springer.com/article/10.1007/s10664-023-10316-9

\section{Proposed Study}
% Detailed description of your research activities – Method section
% • Study Design – enough detail that someone can replicate your study
% • Methods of data collection (e.g. survey, interview, experiment, observation, participatory).
% • Procedure – how will you run your study?
% • Analysis – how will you treat your data?
\subsection{Design}

A survey will be conducted with participants, combined with coding tasks to compare using AI and not using AI. This subjective measurement will facilitate engaging with individuals from very experienced engineers to those still learning including a mix of traditional software developers and those that do not identify traditionally as software developers (DevOps, SRE, infrastructure administrators).

\subsubsection{Strengths and Weaknesses}
The main strength ....... However, it has the same limitations with regard to self-reporting having a potential bias affecting the results;  ......

\subsection{Method}
The procedure and methods will require ethical approval from the University of Northumbria.

\subsubsection{Participants and Procedure}
A survey will be conducted with coding task leveraging AI. The target population are practitioners, including leaders, working in software engineering, software development and DevOps fields that are over the age of 18. 
 
Participants will be recruited be sending the survey invite and instructions out to the  DevOps Research and Assessment (DORA; \cite{Humble2018Accelerate:Organizations}) community of practice \parencite{DORACommunity} email alias in additional to the author's personal network in the industry (LinkedIn, X and internal Google chat spaces) inviting participants to complete the questionnaire. DORA participants were targeted because they are know to be active and passionate individuals excited by topics like software engineering and delivery. The demographic that represents the industry globally is established with 2,250 members in the community and approximately 3,000 participants in the 2023 State of DevOps Report \parencite{2023State2023}.

The questionnaire and tasks are expected to take xx minutes from a device of their choice using their preferred programming language, IDE and AI integration. Should they not have a preferred IDE integration instructions will be provided on how to access and use one.

All participants will be informed about the study via the initial section of the questionnaire and provide their written, informed, consent. The information sheet will include the purpose of the study and why participants have been invited including advantages, disadvantages of participation and anonymity. 
% a copy of these sections can be found in Appendix 1. 

The coding tasks will not validate the answers correctness or accuracy.
% Inclusion criteria ....

% Exclusion criteria .... will not validate answers correctness or accuracy 

The demographic information consisting of age and gender will be requested in additional to the following;

\begin{itemize}
    \item Role
    \item Years of Experience
    \item Average time coding each day
    \item Average time you rely on AI in a day
    \item Assisted Development AI used during the questionnaire (Copilot, DuetAI etc.)
    \item Programming Language Selected (Python, Go, Java, C\# etc.)
\end{itemize}

\subsection{Measures}

A xx item questionnaire consisting of x scales, NASA-TLX and WP, to asses mental workload, xyz will be combined with code challenges from LeetCode \parencite{ProblemsLeetCode}.

% Mental ... will use NASA-TLX and WP (Tsang and Velazquez, 1996)
% Questions from LeetCode \parencite{ProblemsLeetCode} - 
% maybe have a qu that asks you to understand the code?

The questionnaire order and sections will consist of;
\begin{enumerate}
    \item Information Sheet and 
    \item Simple task without AI
    \item Complex task without AI
    \item TLX Survey
    \item Simple task with AI enabled
    \item Complex task with AI enabled
    \item TLX Survey
    \item WP Survey
    \item Demographic and additional questions
\end{enumerate}

\subsubsection{NASA-TLX}
%  Use correct citations and look at rewording thsi section.
NASA Task Load IndeX (TLX) \parencite{Hart1988DevelopmentResearch} is the most commonly used quantitative measure to assess perceived mental workload of a system \parencite{Longo2022HumanDefinition}. 
% TLX has been applied successfully in different multitask contexts, for example in real (Shively,  Battiste,  Matsumoto, Pepiton, Bortolussi, \& Hart, 1987) and simulated flight tasks (Battiste \& Bortolussi, 1988; Corwin, Sandry-Garza,Biferno, Boucek,  Logan, Jonsson, \& Metalis, 1989; Nataupsky \& Abbott, 1987; Tsang \& Johnson, 1989; Vidulich \& Bortolussi, 1988), in air combat (Bittner, Byers, Hill,Zaklad, \& Christ, 1989; Hill, Byers, Zaklad, Christ, \& Bittner, 1988; Hill, Byers, Zaklad, \& Christ, 1989), and using remote-control vehicles (Byers, Bittner,Hill, Zaklad, \& Christ,  1988).

To assess mental workload TLX uses six dimensions, Figure \ref{tab:tlx} shows the dimensions and definitions, with a twenty-step bipolar procedure. Each scale scoring from 0 to 100, to the nearest .5 with the option of combining the six individual ratings in to a global, weighted, score when using a pair comparison task performed prior to the assessment. It should be noted that the weighted score is typically no longer used ......

A  workload  score  from  0  to  100  is  obtained  for  each  rated task  by  multiplying  the  weight  by  the  individual  dimension  scale  score, summing  across  scales,  and  dividing  by  15  (the  total  number  of  paired comparisons).

Originally administered using pen and paper it will be adapted to allow for online completion.

The following are the six subscales, scoring and descriptions.

\begin{table}
    \centering
    \begin{tabular}{ccc}
         Item               & Endpoints         & Description \\
         Mental Demand      &  1-20 (Low/High)  & How much mental and perceptual activity was required? Was the task easy or demanding, simple or complex, exacting or forgiving?\\
         Physical Demand    &  1-20 (Low/High)  & How much physical activity was required? Was the task easy or demanding? Slow or brisk? Slack or strenuous? Restful or laborious? \\
         Temporal Demand    &  1-20 (Low/High)  & How much time pressure did you feel due to the rate or pace at which the tasks or task elements occurred? Was the pace slow and leisurely or rapid and frantic? \\
         Performance        &  1-20 (Good/Poor) & How successful do you think you were in accomplishing the goals of the task set by the experimenter (or yourself)? What is your level of satisfaction? \\
         Effort             &  1-20 (Low/High)  & How hard did you have to work (mentally and physically) to accomplish your level of performance? \\
         Frustration Level  &  1-20 (Low/High)  & \\
    \end{tabular}
    \caption{Rating scale definitions and endpoints from the NASA Task Load Index.}
    \label{tab:tlx}
\end{table}


\subsubsection{Workload Profile}
% "The Workload Profile (WP scale) (Tsang  and  Velazquez, 1996) is a multidimensional way to assess subjective mental workload, based on the multiple resource model of Wickens (1987). Their instrument (Workload Profile) tries to combine the advantages of secondary task performance based procedures (high  diagnosticity) and subjective techniques (high subject acceptability and low implementation requirements and intrusiveness). As Tsang and Velazquez  recognised, the Workload Profile technique needs to be the object of more detailed and extensive research about its properties. The Workload Profile (Tsang & Velazquez, 1996) asks the subjects to provide the proportion of attentional resources used after they had experienced all of the tasks to be rated. The tasks  to be rated are listed in a random order down the column and the eight workload dimensions are listed across the page (see Figure 3). The workload dimensions used in this technique can be defined by the resource dimensions hypothesised in the multiple resource model  of Wickens (1987): perceptual/central  processing, response selection and execution, spatial, processing, verbal processing, visual processing, auditory processing, manual output, and speech  output. Subjects have available to them the definition of each dimension at the time of the rating.In each cell on the rating sheet, subjects provide a number between 0 and 1 to represent the proportion of attentional resources  used in a particular dimension for a particular task. A rating of “0” means that the task placed no demand on the dimension being rated; a rating  of  “1”  means that the task required maximum attention. The ratings on the individual dimensions are  later  summed  for  each  task  to  provide  an  overall  workload  rating."
The Workload Profile (WP scale) developed by Tsang and Velazquez (\citeyear{Tsang1996DiagnosticityRatings}) offers a multidimensional approach for evaluating subjective mental workload. This scale is rooted in Wickens' multiple resource model. Participants assess the proportion of attentional resources utilised after completing various tasks, that are listed in a randomised order. Eight workload dimensions are presented, these workload dimensions correspond to the resource dimensions outlined in Wickens' multiple resource model (1987): perceptual/central processing, response selection and execution, spatial processing, verbal processing, visual processing, auditory processing, manual output, and speech output. Subjects are provided with definitions for each dimension during the rating process.

Participants assign a number between 0 and 1 in each cell, indicating the proportion of attentional resources allocated to a specific dimension for a given task. A rating of "0" implies no demand placed on the rated dimension by the task, while a rating of "1" indicates maximum attention required. The individual dimension ratings are later summed for each task, resulting in an overall workload rating.

WP was selected because the research is comparing mental workload across multiple task that have differing objective levels of difficulty \parencite{Rubio2004EvaluationMethods}.

\begin{table}
    \centering
    \begin{tabular}{ccccccccc}
         & Stage of Processing  & Code of Processing  & Input  & Output & \\
         Task & Perceptual/Central & Response  & Spatial & Verbal & Visual & Auditory & Manual & Speech\\
         Simple &  &  &  &  &  &  &  & \\
         Complex &  &  &  &  &  &  &  & \\
         Simple with AI &  &  &  &  &  &  &  & \\
         Complex with AI &  &  &  &  &  &  &  & \\
    \end{tabular}
    \caption{  Workload  Profile  rating  sheet}
    \label{tab:my_label}
\end{table}

\subsubsection{Tasks}
X tasks used ... from LeetCode ... simple and complex .... maybe a code comprehension 

The effort scale of the Effort-Reward Imbalance model (ERI) consisting of five items (\cite{Siegrist2004TheComparisons}) will be used to measure job demands on a five-point scale from disagree to agree and I am very stressed. The construct validity of the scale over time has been valid (\cite{Rantanen2013FactorialStudies});

\begin{enumerate}
    \item xyz.
    \item zyx.

\end{enumerate}


\subsubsection{Variables and Procedure}

x variables taken into account a) , b), ... and d) the tool used to measure subjective mental workload (TLX and WP)

\subsection{Data Analysis}
...........................

"Each subscale is presented to the participants either during or after the experimental trial. They are asked to rate their score on an interval scale ranging from low (1) to high (20). The TLX also employs a paired comparisons procedure. This involves presenting 15 pairwise combinations to the participants and asking them to select the scale from each pair that has the most effect on the workload during the task under analysis. This procedure accounts for two potential sources of between-rater variability: differences in workload definition between the raters and differences in the sources or workload between the tasks.


"Validating the NASA-TLX was critical to show that subscale ratings could be combined into a single overall workload score. This has traditionally been done using one of two methods:

Weighted combination – users are shown all 15 pairwise comparisons of dimensions (e.g., Mental Demand vs. Physical Demand, Effort vs. Performance, and so on) and asked to select which better represented their experience of demand. The number of times a dimension was selected determines its weight (or importance) and the weights are then multiplied by raw ratings and either averaged or summed into an overall score.
Unweighted combination
Unweighted combination – users do not perform the pairwise comparisons procedure. Instead, raw ratings from each subscale are simply averaged or summed into an overall score, which assumes that each dimension was equally important (this is often referred to as a Raw-TLX, or RTLX, score; Hart, 2006)." - https://research-collective.com/nasa-tlx/

The subscales are given to the participants either during or following their experimental trial. The participants self-rate on a scale of 1 (low) to 20 (high) using 15 pairwise combinations designed to elicit from the participants the pair that has the greatest effect on workload while performing the task."

NOTE STARTED TO WRITE THIS BIT YET...
The distinctiveness of the profile will be assessed using the Average latent class Posterior Probabilities (AvePP), which evaluates using posterior probabilities the certainty of profile placement and the entropy that evaluates the accuracy of classifications (\cite{Jung2008AnModeling}).

Univariable analysis of variance between the differences in antecedents of the burnout profiles will occur. General Linear Model (GLM) will be used to investigate burnout profiles with respect to job demands and job resources over time. 

To investigate statistical significance of changes in mean levels for each of the burnout profiles, ANOVA will be used. 

Demographic data will be reviewed to ensure that systematic attrition does not occur with the study variable and backgrounds. 

Anonomysation of data - De-identified – you have removed emails and provided a number/code

\printbibliography
\end{document}